{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c7b9d28",
   "metadata": {},
   "source": [
    "### Construir um conjunto de modelos preditivos, para prever o CCS (Concrete Compressive Strength) do concreto a partir das variáveis de entrada (ingredientes) oferecidos para produção do concreto. Automatizar o processo para futuros experimentos da equipe, e escolher o modelo mais eficiente para a produção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a5df2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Findspark\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b24a2b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import * \n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.regression import *\n",
    "from pyspark.ml.evaluation import *\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476683de",
   "metadata": {},
   "source": [
    "#### Ambiente Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6add07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/02/10 21:11:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Spark Context\n",
    "sc = SparkContext(appName = \"MLConcreto\")\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c61f6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0274105c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.4:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>MLConcreto</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x10f323e50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6ea7d9",
   "metadata": {},
   "source": [
    "#### Carga de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79bd43a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando os dados\n",
    "dados = spark.read.csv('dados/dataset.csv', inferSchema = True, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84c79e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1030"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd035bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+------+-----+----------------+---------------+-------------+---+-----+\n",
      "|cement| slag|flyash|water|superplasticizer|coarseaggregate|fineaggregate|age|csMPa|\n",
      "+------+-----+------+-----+----------------+---------------+-------------+---+-----+\n",
      "| 540.0|  0.0|   0.0|162.0|             2.5|         1040.0|        676.0| 28|79.99|\n",
      "| 540.0|  0.0|   0.0|162.0|             2.5|         1055.0|        676.0| 28|61.89|\n",
      "| 332.5|142.5|   0.0|228.0|             0.0|          932.0|        594.0|270|40.27|\n",
      "| 332.5|142.5|   0.0|228.0|             0.0|          932.0|        594.0|365|41.05|\n",
      "| 198.6|132.4|   0.0|192.0|             0.0|          978.4|        825.5|360| 44.3|\n",
      "+------+-----+------+-----+----------------+---------------+-------------+---+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dados.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8aa05f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>slag</th>\n",
       "      <th>flyash</th>\n",
       "      <th>water</th>\n",
       "      <th>superplasticizer</th>\n",
       "      <th>coarseaggregate</th>\n",
       "      <th>fineaggregate</th>\n",
       "      <th>age</th>\n",
       "      <th>csMPa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>266.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>90</td>\n",
       "      <td>47.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>380.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>43.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>380.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>28</td>\n",
       "      <td>36.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>266.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>28</td>\n",
       "      <td>45.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>475.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>28</td>\n",
       "      <td>39.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cement   slag  flyash  water  superplasticizer  coarseaggregate  \\\n",
       "0   540.0    0.0     0.0  162.0               2.5           1040.0   \n",
       "1   540.0    0.0     0.0  162.0               2.5           1055.0   \n",
       "2   332.5  142.5     0.0  228.0               0.0            932.0   \n",
       "3   332.5  142.5     0.0  228.0               0.0            932.0   \n",
       "4   198.6  132.4     0.0  192.0               0.0            978.4   \n",
       "5   266.0  114.0     0.0  228.0               0.0            932.0   \n",
       "6   380.0   95.0     0.0  228.0               0.0            932.0   \n",
       "7   380.0   95.0     0.0  228.0               0.0            932.0   \n",
       "8   266.0  114.0     0.0  228.0               0.0            932.0   \n",
       "9   475.0    0.0     0.0  228.0               0.0            932.0   \n",
       "\n",
       "   fineaggregate  age  csMPa  \n",
       "0          676.0   28  79.99  \n",
       "1          676.0   28  61.89  \n",
       "2          594.0  270  40.27  \n",
       "3          594.0  365  41.05  \n",
       "4          825.5  360  44.30  \n",
       "5          670.0   90  47.03  \n",
       "6          594.0  365  43.70  \n",
       "7          594.0   28  36.45  \n",
       "8          670.0   28  45.85  \n",
       "9          594.0   28  39.29  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Formato do Pandas\n",
    "dados.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12c05f1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cement: double (nullable = true)\n",
      " |-- slag: double (nullable = true)\n",
      " |-- flyash: double (nullable = true)\n",
      " |-- water: double (nullable = true)\n",
      " |-- superplasticizer: double (nullable = true)\n",
      " |-- coarseaggregate: double (nullable = true)\n",
      " |-- fineaggregate: double (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- csMPa: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Schema\n",
    "dados.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c072568",
   "metadata": {},
   "source": [
    "#### Automação da Preparação de Dados"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a3b9f638",
   "metadata": {},
   "source": [
    "    O MLlib exige que as colunas de entrada do dataframe sejam vetorizadas. Os dados já estão sem valores ausentes ou nulos, logo esse tratamento não será necessário. Criaremos uma função Python que irá automatizar o processo de todas as tarefas necessárias para preparação dos dados, incluindo a vetorização.\n",
    "A função será um fluxo de trabalho que vai receber as variáveis de entrada, de saída, a necessidade ou não de tratar outliers, bem como a necessidade ou não de padronizar os dados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff21c58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para preparação dos dados\n",
    "def func_modulo_prep_dados(df,\n",
    "                           variaveis_entrada,\n",
    "                           variavel_saida,\n",
    "                           tratar_outliers = True,\n",
    "                           padronizar_dados = True):\n",
    "\n",
    "    # Vamos gerar um novo dataframe, renomeando a variável de saída exigido pelo Spark.\n",
    "    novo_df = df.withColumnRenamed(variavel_saida, 'label')\n",
    "    \n",
    "    # Converter a variável alvo para float\n",
    "    if str(novo_df.schema['label'].dataType) != 'IntegerType':\n",
    "        novo_df = novo_df.withColumn(\"label\", novo_df[\"label\"].cast(FloatType()))\n",
    "    \n",
    "    # Listas de controle para as variáveis\n",
    "    variaveis_numericas = []\n",
    "    variaveis_categoricas = []\n",
    "    \n",
    "    # Havendo variáveis string converte para numérico\n",
    "    for coluna in variaveis_entrada:\n",
    "        \n",
    "        # Verifica se é string\n",
    "        if str(novo_df.schema[coluna].dataType) == 'StringType':\n",
    "            \n",
    "            # Define a variável com um sufixo para tratamento mais tarde\n",
    "            novo_nome_coluna = coluna + \"_num\"\n",
    "            \n",
    "            # Adicionamos à lista de variáveis categóricas\n",
    "            variaveis_categoricas.append(novo_nome_coluna)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # Se não for string adiciona a lista numerica\n",
    "            variaveis_numericas.append(coluna)\n",
    "            \n",
    "            # Coloca os dados no dataframe de variáveis indexadas\n",
    "            df_indexed = novo_df\n",
    "            \n",
    "            \n",
    "    # Se o dataframe tiver dados string, aplica indexação\n",
    "    if len(variaveis_categoricas) != 0: \n",
    "        \n",
    "        for coluna in novo_df:\n",
    "            \n",
    "            # Para variável string, cria, treina e aplica o indexador\n",
    "            if str(novo_df.schema[coluna].dataType) == 'StringType':\n",
    "                \n",
    "                # Cria o indexador\n",
    "                indexer = StringIndexer(inputCol = coluna, outputCol = coluna + \"_num\") \n",
    "                \n",
    "                # Treina e aplica o indexador\n",
    "                df_indexed = indexer.fit(novo_df).transform(novo_df)\n",
    "    else:\n",
    "        \n",
    "        # Não havendo categórica, coloca os dados no dataframe de variáveis indexadas\n",
    "        df_indexed = novo_df\n",
    "        \n",
    "        \n",
    "        \n",
    "    # Tratamento de outliers\n",
    "    if tratar_outliers == True:\n",
    "        print(\"\\nAplicando o tratamento de outliers...\")\n",
    "        \n",
    "        # Dicionário\n",
    "        d = {}\n",
    "        \n",
    "        # Dicionário de quartis das variáveis do dataframe indexado\n",
    "        for col in variaveis_numericas: \n",
    "            d[col] = df_indexed.approxQuantile(col,[0.01, 0.99], 0.25) \n",
    "        \n",
    "        # Aplica a transformação a partir da distribuição de cada variável\n",
    "        for col in variaveis_numericas:\n",
    "            \n",
    "            # Extração da assimetria dos dados\n",
    "            skew = df_indexed.agg(skewness(df_indexed[col])).collect() \n",
    "            skew = skew[0][0]\n",
    "            \n",
    "            # Transformação de log + 1 se a assimetria for positiva\n",
    "            if skew > 1:\n",
    "                indexed = df_indexed.withColumn(col, log(when(df[col] < d[col][0], d[col][0])\\\n",
    "                .when(df_indexed[col] > d[col][1], d[col][1])\\\n",
    "                .otherwise(df_indexed[col] ) + 1).alias(col))\n",
    "                print(\"\\nA variável \" + col + \" foi tratada para assimetria positiva com skew =\", skew)\n",
    "            \n",
    "            # Transformação exponencial se a assimetria for negativa\n",
    "            elif skew < -1:\n",
    "                indexed = df_indexed.withColumn(col, \\\n",
    "                exp(when(df[col] < d[col][0], d[col][0])\\\n",
    "                .when(df_indexed[col] > d[col][1], d[col][1])\\\n",
    "                .otherwise(df_indexed[col] )).alias(col))\n",
    "                print(\"\\nA variável \" + col + \" foi tratada para assimetria negativa com skew =\", skew)\n",
    "\n",
    "                \n",
    "                \n",
    "    # Vetorização para Spark\n",
    "    \n",
    "    # Lista final de atributos concatenando variáveis\n",
    "    lista_atributos = variaveis_numericas + variaveis_categoricas\n",
    "    \n",
    "    # Cria o vetorizador para os atributos\n",
    "    vetorizador = VectorAssembler(inputCols = lista_atributos, outputCol = 'features')\n",
    "    \n",
    "    # Aplica o vetorizador ao conjunto de dados\n",
    "    dados_vetorizados = vetorizador.transform(df_indexed).select('features', 'label')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Padronização dos dados \n",
    "    if padronizar_dados == True:\n",
    "        print(\"\\nPadronizando o conjunto de dados para o intervalo entre 0 a 1...\")\n",
    "        \n",
    "        # Scaler\n",
    "        scaler = MinMaxScaler(inputCol = \"features\", outputCol = \"scaledFeatures\")\n",
    "\n",
    "        # Padronizador, e globalizando variável para uso fora da funç.\n",
    "        global scalerModel\n",
    "        scalerModel = scaler.fit(dados_vetorizados)\n",
    "\n",
    "        # Padroniza as variáveis para o intervalo [min, max]\n",
    "        dados_padronizados = scalerModel.transform(dados_vetorizados)\n",
    "        \n",
    "        # Gera os dados finais\n",
    "        dados_finais = dados_padronizados.select('label', 'scaledFeatures')\n",
    "        \n",
    "        # Renomeia as colunas como requerido pelo Spark\n",
    "        dados_finais = dados_finais.withColumnRenamed('scaledFeatures', 'features')\n",
    "        \n",
    "        print(\"\\nProcesso Concluído!\")\n",
    "\n",
    "    # Não havendo necessidade\n",
    "    else:\n",
    "        print(\"\\nOs dados não serão padronizados.\")\n",
    "        dados_finais = dados_vetorizados\n",
    "    \n",
    "    return dados_finais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0c742c",
   "metadata": {},
   "source": [
    "#### Preparação dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e571546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variáveis de entrada\n",
    "variaveis_entrada = dados.columns[:-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad80fe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target\n",
    "variavel_saida = dados.columns[-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "573c7451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aplicando o tratamento de outliers...\n",
      "\n",
      "A variável age foi tratada para assimetria positiva (direita) com skew = 3.2644145354168086\n",
      "\n",
      "Padronizando o conjunto de dados para o intervalo entre 0 a 1...\n",
      "\n",
      "Processo Concluído!\n"
     ]
    }
   ],
   "source": [
    "# Aplica a função\n",
    "dados_finais = func_modulo_prep_dados(dados, variaveis_entrada, variavel_saida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c7ab2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------------------------------------------------------------------------------------------------------------+\n",
      "|label|features                                                                                                                 |\n",
      "+-----+-------------------------------------------------------------------------------------------------------------------------+\n",
      "|79.99|[1.0,0.0,0.0,0.3210862619808307,0.07763975155279502,0.6947674418604651,0.20572002007024587,0.07417582417582418]          |\n",
      "|61.89|[1.0,0.0,0.0,0.3210862619808307,0.07763975155279502,0.7383720930232558,0.20572002007024587,0.07417582417582418]          |\n",
      "|40.27|[0.526255707762557,0.3964941569282137,0.0,0.8482428115015974,0.0,0.3808139534883721,0.0,0.739010989010989]               |\n",
      "|41.05|[0.526255707762557,0.3964941569282137,0.0,0.8482428115015974,0.0,0.3808139534883721,0.0,1.0]                             |\n",
      "|44.3 |[0.22054794520547943,0.3683917640511965,0.0,0.560702875399361,0.0,0.5156976744186046,0.58078273958856,0.9862637362637363]|\n",
      "+-----+-------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualiza\n",
    "dados_finais.show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2085110a",
   "metadata": {},
   "source": [
    "#### Verificando Correlação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "000e428a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Extrai a correlação com coef. de Pearson\n",
    "coeficientes_corr = Correlation.corr(dados_finais, 'features', 'pearson').collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c851f948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo em array\n",
    "array_corr = coeficientes_corr.toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42f675bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.27521591, -0.39746734, -0.08158675,  0.09238617,\n",
       "        -0.10934899, -0.22271785,  0.08194602],\n",
       "       [-0.27521591,  1.        , -0.3235799 ,  0.10725203,  0.04327042,\n",
       "        -0.28399861, -0.28160267, -0.04424602],\n",
       "       [-0.39746734, -0.3235799 ,  1.        , -0.25698402,  0.37750315,\n",
       "        -0.00996083,  0.07910849, -0.15437052],\n",
       "       [-0.08158675,  0.10725203, -0.25698402,  1.        , -0.65753291,\n",
       "        -0.1822936 , -0.45066117,  0.27761822],\n",
       "       [ 0.09238617,  0.04327042,  0.37750315, -0.65753291,  1.        ,\n",
       "        -0.26599915,  0.22269123, -0.19270003],\n",
       "       [-0.10934899, -0.28399861, -0.00996083, -0.1822936 , -0.26599915,\n",
       "         1.        , -0.17848096, -0.00301588],\n",
       "       [-0.22271785, -0.28160267,  0.07910849, -0.45066117,  0.22269123,\n",
       "        -0.17848096,  1.        , -0.1560947 ],\n",
       "       [ 0.08194602, -0.04424602, -0.15437052,  0.27761822, -0.19270003,\n",
       "        -0.00301588, -0.1560947 ,  1.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c47a61fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08194602387182176\n",
      "-0.044246019304454175\n",
      "-0.15437051606792915\n",
      "0.27761822152100296\n",
      "-0.19270002804347258\n",
      "-0.0030158803467436645\n",
      "-0.15609470264758615\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Correlação entre os atributos e a variável alvo\n",
    "for item in array_corr:\n",
    "    print(item[7])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ba91fd1b",
   "metadata": {},
   "source": [
    "    A partir da correlação da variável alvo com as variáveis de entrada, podemos perceber que nem todas as variáveis apresentam uma boa correlação com a target. Mesmo assim, conversando com a equipe, nossa escolha será levar todas as variáveis a diante para o modelo, a fim de que possa possivelmente compreender melhor o padrão dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a78d82",
   "metadata": {},
   "source": [
    "#### Machine Learning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "400f99a7",
   "metadata": {},
   "source": [
    "                                            Módulo de AutoML\n",
    "    Vamos criar uma função para automatizar o uso de diversos algoritmos, multiplas vezes cada um destes. Nossa função irá criar, treinar e avaliar cada um dos algorítimos com diferentes combinações de hiperparâmetros. E então escolheremos o melhor modelo de cada modelo, e dentre todos os modelos, o que apresentar melhor performance.\n",
    "A função recebe algoritmo como entrada, verifica o algorítmo e executa o código específico para tal, utiliza validação cruzada, constroi os avaliadores RMSE (erro) e R2 (acurácia), escolhe o melhor modelo, e entra no loop para execução do algorítmo imprimindo as métricas. Então seleciona o melhor modelo de cada algorítmo e faz as previsões, extraindo as métricas de eficiência, e salva no Data Frame de resultados para comparação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05347ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão em treino e teste 70/30\n",
    "dados_treino, dados_teste = dados_finais.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f59af723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de algoritmos\n",
    "regressores = [LinearRegression(),\n",
    "               DecisionTreeRegressor(),\n",
    "               RandomForestRegressor(),\n",
    "               GBTRegressor(),\n",
    "               IsotonicRegression()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "780f6773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Módulo de Auto ML\n",
    "def func_modulo_ml(algoritmo_regressao):\n",
    "\n",
    "    # Obter o tipo do algoritmo e criar a instância do objeto\n",
    "    def func_tipo_algo(algo_regressao):\n",
    "        algoritmo = algo_regressao\n",
    "        tipo_algo = type(algoritmo).__name__\n",
    "        return tipo_algo\n",
    "    \n",
    "    # Aplica\n",
    "    tipo_algo = func_tipo_algo(algoritmo_regressao)\n",
    "\n",
    "    # Para Regressão Linear\n",
    "    if tipo_algo == \"LinearRegression\":\n",
    "        \n",
    "        # Primeira versão sem validação cruzada\n",
    "        modelo = regressor.fit(dados_treino)\n",
    "        \n",
    "        # Métricas do modelo\n",
    "        print('\\033[1m' + \"Modelo de Regressão Linear Sem Validação Cruzada:\" + '\\033[0m')\n",
    "        print(\"\")\n",
    "        \n",
    "        # Avalia com dados de teste\n",
    "        resultado_teste = modelo.evaluate(dados_teste)\n",
    "\n",
    "        # Métricas de erro do modelo com dados de teste\n",
    "        print(\"RMSE em Teste: {}\".format(resultado_teste.rootMeanSquaredError))\n",
    "        print(\"Coeficiente R2 em Teste: {}\".format(resultado_teste.r2))\n",
    "        print(\"\")\n",
    "        \n",
    "        \n",
    "        # Segunda versão, usando validação cruzada\n",
    "        \n",
    "        # Grid de hiperparâmetros\n",
    "        paramGrid = (ParamGridBuilder().addGrid(regressor.regParam, [0.1, 0.01]).build())\n",
    "        \n",
    "        # Cria os avaliadores\n",
    "        eval_rmse = RegressionEvaluator(metricName = \"rmse\")\n",
    "        eval_r2 = RegressionEvaluator(metricName = \"r2\")\n",
    "        \n",
    "        # Cross Validator\n",
    "        crossval = CrossValidator(estimator = regressor,\n",
    "                                  estimatorParamMaps = paramGrid,\n",
    "                                  evaluator = eval_rmse,\n",
    "                                  numFolds = 3) \n",
    "        \n",
    "        print('\\033[1m' + \"Modelo de Regressão Linear Com Validação Cruzada:\" + '\\033[0m')\n",
    "        print(\"\")\n",
    "        \n",
    "        # Treina modelo com validação cruzada\n",
    "        modelo = crossval.fit(dados_treino)\n",
    "        \n",
    "        # Salva o melhor modelo da versão 2\n",
    "        global LR_BestModel \n",
    "        LR_BestModel = modelo.bestModel\n",
    "                \n",
    "        # Previsões com dados de teste\n",
    "        previsoes = LR_BestModel.transform(dados_teste)\n",
    "        \n",
    "        # Avaliação do melhor modelo\n",
    "        resultado_teste_rmse = eval_rmse.evaluate(previsoes)\n",
    "        print('RMSE em Teste:', resultado_teste_rmse)\n",
    "        \n",
    "        resultado_teste_r2 = eval_r2.evaluate(previsoes)\n",
    "        print('Coeficiente R2 em Teste:', resultado_teste_r2)\n",
    "        print(\"\")\n",
    "    \n",
    "        # Lista de colunas dataframe de resumo\n",
    "        columns = ['Regressor', 'Resultado_RMSE', 'Resultado_R2']\n",
    "        \n",
    "        # Formata as métricas e nome do algoritmo\n",
    "        rmse_str = [str(resultado_teste_rmse)] \n",
    "        r2_str = [str(resultado_teste_r2)] \n",
    "        tipo_algo = [tipo_algo] \n",
    "        \n",
    "        # Cria o dataframne de resumo\n",
    "        df_resultado = spark.createDataFrame(zip(tipo_algo, rmse_str, r2_str), schema = columns)\n",
    "        \n",
    "        # Grava os resultados no dataframe\n",
    "        df_resultado = df_resultado.withColumn('Resultado_RMSE', df_resultado.Resultado_RMSE.substr(0, 5))\n",
    "        df_resultado = df_resultado.withColumn('Resultado_R2', df_resultado.Resultado_R2.substr(0, 5))\n",
    "        \n",
    "        return df_resultado\n",
    "\n",
    "    else:\n",
    "        \n",
    "        # Para Decision Tree\n",
    "        if tipo_algo in(\"DecisionTreeRegressor\"):\n",
    "            paramGrid = (ParamGridBuilder().addGrid(regressor.maxBins, [10, 20, 40]).build())\n",
    "\n",
    "        # Para Random Forest \n",
    "        if tipo_algo in(\"RandomForestRegressor\"):\n",
    "            paramGrid = (ParamGridBuilder().addGrid(regressor.numTrees, [5, 10, 20]).build())\n",
    "\n",
    "        # Para GBT \n",
    "        if tipo_algo in(\"GBTRegressor\"):\n",
    "            paramGrid = (ParamGridBuilder() \\\n",
    "                         .addGrid(regressor.maxBins, [10, 20]) \\\n",
    "                         .addGrid(regressor.maxIter, [10, 15])\n",
    "                         .build())\n",
    "            \n",
    "        # Para Isotonic \n",
    "        if tipo_algo in(\"IsotonicRegression\"):\n",
    "            paramGrid = (ParamGridBuilder().addGrid(regressor.isotonic, [True, False]).build())\n",
    "\n",
    "\n",
    "        # Cria os avaliadores\n",
    "        eval_rmse = RegressionEvaluator(metricName = \"rmse\")\n",
    "        eval_r2 = RegressionEvaluator(metricName = \"r2\")\n",
    "        \n",
    "        \n",
    "        # Prepara o Cross Validator\n",
    "        crossval = CrossValidator(estimator = regressor,\n",
    "                                  estimatorParamMaps = paramGrid,\n",
    "                                  evaluator = eval_rmse,\n",
    "                                  numFolds = 3) \n",
    "        \n",
    "        \n",
    "        # Treina o modelo usando validação cruzada\n",
    "        modelo = crossval.fit(dados_treino)\n",
    "        \n",
    "        \n",
    "        # Extrai o melhor modelo\n",
    "        BestModel = modelo.bestModel\n",
    "\n",
    "        \n",
    "        # Resumo de cada modelo\n",
    "        # Métricas do modelo\n",
    "        if tipo_algo in(\"DecisionTreeRegressor\"):\n",
    "            \n",
    "            # Variável global\n",
    "            global DT_BestModel \n",
    "            DT_BestModel = modelo.bestModel\n",
    "            \n",
    "            # Previsões com dados de teste\n",
    "            previsoes_DT = DT_BestModel.transform(dados_teste)\n",
    "            \n",
    "            print('\\033[1m' + \"Modelo Decision Tree Com Validação Cruzada:\" + '\\033[0m')\n",
    "            print(\" \")\n",
    "            \n",
    "            # Avaliação do modelo\n",
    "            resultado_teste_rmse = eval_rmse.evaluate(previsoes_DT)\n",
    "            print('RMSE em Teste:', resultado_teste_rmse)\n",
    "        \n",
    "            resultado_teste_r2 = eval_r2.evaluate(previsoes_DT)\n",
    "            print('Coeficiente R2 em Teste:', resultado_teste_r2)\n",
    "            print(\"\")\n",
    "        \n",
    "        # Métricas do modelo\n",
    "        if tipo_algo in(\"RandomForestRegressor\"):\n",
    "            \n",
    "            # Variável global\n",
    "            global RF_BestModel \n",
    "            RF_BestModel = modelo.bestModel\n",
    "            \n",
    "            # Previsões com dados de teste\n",
    "            previsoes_RF = RF_BestModel.transform(dados_teste)\n",
    "            \n",
    "            print('\\033[1m' + \"Modelo RandomForest Com Validação Cruzada:\" + '\\033[0m')\n",
    "            print(\" \")\n",
    "            \n",
    "            # Avaliação do modelo\n",
    "            resultado_teste_rmse = eval_rmse.evaluate(previsoes_RF)\n",
    "            print('RMSE em Teste:', resultado_teste_rmse)\n",
    "        \n",
    "            resultado_teste_r2 = eval_r2.evaluate(previsoes_RF)\n",
    "            print('Coeficiente R2 em Teste:', resultado_teste_r2)\n",
    "            print(\"\")\n",
    "        \n",
    "        # Métricas do modelo\n",
    "        if tipo_algo in(\"GBTRegressor\"):\n",
    "\n",
    "            # Variável global\n",
    "            global GBT_BestModel \n",
    "            GBT_BestModel = modelo.bestModel\n",
    "            \n",
    "            # Previsões com dados de teste\n",
    "            previsoes_GBT = GBT_BestModel.transform(dados_teste)\n",
    "            \n",
    "            print('\\033[1m' + \"Modelo Gradient-Boosted Tree (GBT) Com Validação Cruzada:\" + '\\033[0m')\n",
    "            print(\" \")\n",
    "            \n",
    "            # Avaliação do modelo\n",
    "            resultado_teste_rmse = eval_rmse.evaluate(previsoes_GBT)\n",
    "            print('RMSE em Teste:', resultado_teste_rmse)\n",
    "        \n",
    "            resultado_teste_r2 = eval_r2.evaluate(previsoes_GBT)\n",
    "            print('Coeficiente R2 em Teste:', resultado_teste_r2)\n",
    "            print(\"\")\n",
    "            \n",
    "        # Métricas do modelo\n",
    "        if tipo_algo in(\"IsotonicRegression\"):\n",
    "\n",
    "            # Variável global\n",
    "            global ISO_BestModel \n",
    "            ISO_BestModel = modelo.bestModel\n",
    "            \n",
    "            # Previsões com dados de teste\n",
    "            previsoes_ISO = ISO_BestModel.transform(dados_teste)\n",
    "            \n",
    "            print('\\033[1m' + \"Modelo Isotonic Com Validação Cruzada:\" + '\\033[0m')\n",
    "            print(\" \")\n",
    "            \n",
    "            # Avaliação do modelo\n",
    "            resultado_teste_rmse = eval_rmse.evaluate(previsoes_ISO)\n",
    "            print('RMSE em Teste:', resultado_teste_rmse)\n",
    "        \n",
    "            resultado_teste_r2 = eval_r2.evaluate(previsoes_ISO)\n",
    "            print('Coeficiente R2 em Teste:', resultado_teste_r2)\n",
    "            print(\"\")\n",
    "                   \n",
    "                \n",
    "        # Lista de colunas\n",
    "        columns = ['Regressor', 'Resultado_RMSE', 'Resultado_R2']\n",
    "        \n",
    "        \n",
    "        # Previsões com dados de teste\n",
    "        previsoes = modelo.transform(dados_teste)\n",
    "        \n",
    "        \n",
    "        # Avalia o modelo\n",
    "        eval_rmse = RegressionEvaluator(metricName = \"rmse\")\n",
    "        rmse = eval_rmse.evaluate(previsoes)\n",
    "        rmse_str = [str(rmse)]\n",
    "        \n",
    "        eval_r2 = RegressionEvaluator(metricName = \"r2\")\n",
    "        r2 = eval_r2.evaluate(previsoes)\n",
    "        r2_str = [str(r2)]\n",
    "         \n",
    "        tipo_algo = [tipo_algo] \n",
    "        \n",
    "        \n",
    "        # Cria o dataframe\n",
    "        df_resultado = spark.createDataFrame(zip(tipo_algo, rmse_str, r2_str), schema = columns)\n",
    "        \n",
    "        \n",
    "        # Grava o resultado no dataframe\n",
    "        df_resultado = df_resultado.withColumn('Resultado_RMSE', df_resultado.Resultado_RMSE.substr(0, 5))\n",
    "        df_resultado = df_resultado.withColumn('Resultado_R2', df_resultado.Resultado_R2.substr(0, 5))\n",
    "        \n",
    "        \n",
    "        return df_resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e58ee158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colunas e valores\n",
    "colunas = ['Regressor', 'Resultado_RMSE', 'Resultado_R2']\n",
    "valores = [(\"N/A\", \"N/A\", \"N/A\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7748097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela de resumo\n",
    "df_resultados_treinamento = spark.createDataFrame(valores, colunas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1e64385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mModelo de Regressão Linear Sem Validação Cruzada:\u001b[0m\n",
      "\n",
      "RMSE em Teste: 10.131478111661103\n",
      "Coeficiente R2 em Teste: 0.6378209342710394\n",
      "\n",
      "\u001b[1mModelo de Regressão Linear Com Validação Cruzada:\u001b[0m\n",
      "\n",
      "RMSE em Teste: 10.131058302562344\n",
      "Coeficiente R2 em Teste: 0.6378509482365038\n",
      "\n",
      "\u001b[1mModelo Decision Tree Com Validação Cruzada:\u001b[0m\n",
      " \n",
      "RMSE em Teste: 9.161036559296653\n",
      "Coeficiente R2 em Teste: 0.7038805352591408\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/Users/emerson/anaconda3/lib/python3.11/site-packages/pyspark/jars/spark-core_2.12-3.5.0.jar) to field java.nio.charset.Charset.name\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mModelo RandomForest Com Validação Cruzada:\u001b[0m\n",
      " \n",
      "RMSE em Teste: 7.682086955630076\n",
      "Coeficiente R2 em Teste: 0.791773422660956\n",
      "\n",
      "\u001b[1mModelo Gradient-Boosted Tree (GBT) Com Validação Cruzada:\u001b[0m\n",
      " \n",
      "RMSE em Teste: 6.954546124882646\n",
      "Coeficiente R2 em Teste: 0.82934645796339\n",
      "\n",
      "\u001b[1mModelo Isotonic Com Validação Cruzada:\u001b[0m\n",
      " \n",
      "RMSE em Teste: 14.136438977111792\n",
      "Coeficiente R2 em Teste: 0.2948885473415652\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop de treinamento\n",
    "for regressor in regressores:\n",
    "    \n",
    "    # Resultado para cada regressor\n",
    "    resultado_modelo = func_modulo_ml(regressor)\n",
    "    \n",
    "    # Grava os resultados\n",
    "    df_resultados_treinamento = df_resultados_treinamento.union(resultado_modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77eea243",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2152:==================================>                   (12 + 4) / 19]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------------+------------+\n",
      "|Regressor            |Resultado_RMSE|Resultado_R2|\n",
      "+---------------------+--------------+------------+\n",
      "|LinearRegression     |10.13         |0.637       |\n",
      "|DecisionTreeRegressor|9.161         |0.703       |\n",
      "|RandomForestRegressor|7.682         |0.791       |\n",
      "|GBTRegressor         |6.954         |0.829       |\n",
      "|IsotonicRegression   |14.13         |0.294       |\n",
      "+---------------------+--------------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 2152:=============================================>        (16 + 3) / 19]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Retorna as linhas diferentes de N/A\n",
    "df_resultados_treinamento = df_resultados_treinamento.where(\"Regressor!='N/A'\")\n",
    "df_resultados_treinamento.show(10, False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b57e9afb",
   "metadata": {},
   "source": [
    "        A partir das métricas de avaliação, podemos ver que o modelo GBT apresentou melhor performance nas duas métricas avaliativas, obtendo o RMSE (erro, quanto menor melhor) de 6.95 e o R2(acurácia, quanto maior melhor) de 0.829. Logo, será o modelo selecionado para ser levado a frente para a produção."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142d8eec",
   "metadata": {},
   "source": [
    "#### Fazendo Previsões com o Modelo Treinado"
   ]
  },
  {
   "cell_type": "raw",
   "id": "601b7445",
   "metadata": {},
   "source": [
    "    Para realizar as previsões com novos dados, temos que realizar os mesmos processos de tratamento nos novos dados, realizados nos dados utilizados para treinar o modelo, pois é o que o modelo espera a partir da sua construção e sequenciamento de tarefas. Logo, criaremos um data frame com o valor das variáveis de entrada, aplicaremos a normalização de dados na coluna \"age\", vetorizaremos os dados, padronizaremos os dados e então realizamos as novas previsões utilizando o melhor modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c9be2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores de entrada\n",
    "values = [(540,0.0,0.0,162,2.5,1040,676,28)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e32d696c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nomes das colunas\n",
    "column_names = dados.columns\n",
    "column_names = column_names[0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a07140da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associa valores aos nomes de coluna\n",
    "novos_dados = spark.createDataFrame(values, column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e9f3445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformação aplicada na coluna age\n",
    "novos_dados = novos_dados.withColumn(\"age\", log(\"age\") +1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a077afc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de atributos\n",
    "lista_atributos = [\"cement\",\n",
    "                   \"slag\",\n",
    "                   \"flyash\",\n",
    "                   \"water\",\n",
    "                   \"superplasticizer\",\n",
    "                   \"coarseaggregate\",\n",
    "                   \"fineaggregate\",\n",
    "                   \"age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e6eae239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vetorizador\n",
    "assembler = VectorAssembler(inputCols = lista_atributos, outputCol = 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bda00ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforma dados em vetor\n",
    "novos_dados = assembler.transform(novos_dados).select('features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a7eff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padroniza os dados\n",
    "novos_dados_scaled = scalerModel.transform(novos_dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da17ab95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleciona a coluna resultante\n",
    "novos_dados_final = novos_dados_scaled.select('scaledFeatures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "159159e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomeia a coluna \n",
    "novos_dados_final = novos_dados_final.withColumnRenamed('scaledFeatures','features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bfeea1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões com novos dados usando melhor modelo\n",
    "previsoes_novos_dados = GBT_BestModel.transform(novos_dados_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6aeefe44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|            features|       prediction|\n",
      "+--------------------+-----------------+\n",
      "|[1.0,0.0,0.0,0.32...|40.59330248869691|\n",
      "+--------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Resultado\n",
    "previsoes_novos_dados.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5e1a693c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cement',\n",
       " 'slag',\n",
       " 'flyash',\n",
       " 'water',\n",
       " 'superplasticizer',\n",
       " 'coarseaggregate',\n",
       " 'fineaggregate',\n",
       " 'age']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a40c12c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(540, 0.0, 0.0, 162, 2.5, 1040, 676, 28)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b056f43e",
   "metadata": {},
   "source": [
    "    Segundo a previsão do nosso modelo, o cimento composto pela medida referente aos valores das variáveis de entrada (ingredientes: cement 540, slag 0.0, flyash 0.0, water 162, superplasticizer 2.5, fineaggregate 1040, 676, age 28) terá um valor de 40.593CCS (Concrete Compressive Strength)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
